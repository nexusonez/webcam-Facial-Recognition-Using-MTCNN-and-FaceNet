{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayTBV50uWeFA"
      },
      "source": [
        "1. Install python then setup MTCNN and FaceNet. Deep-learning frameworks like tensorflow and pytorch are required to run MTCNN and FaceNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4PRhARKVhR9",
        "outputId": "91dad288-d05d-46b2-ee4f-8a409cb5cc9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pip in c:\\program files\\python310\\lib\\site-packages (22.2.1)\n",
            "Collecting pip\n",
            "  Using cached pip-24.0-py3-none-any.whl (2.1 MB)\n",
            "Installing collected packages: pip\n",
            "Successfully installed pip-24.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.2.1 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "Requirement already satisfied: opencv-python in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from opencv-python) (1.26.4)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting facenet-pytorch\n",
            "  Using cached facenet_pytorch-2.5.3-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from facenet-pytorch) (1.26.4)\n",
            "Requirement already satisfied: requests in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from facenet-pytorch) (2.31.0)\n",
            "Collecting torchvision (from facenet-pytorch)\n",
            "  Using cached torchvision-0.17.1-cp310-cp310-win_amd64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pillow in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from facenet-pytorch) (10.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from requests->facenet-pytorch) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from requests->facenet-pytorch) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from requests->facenet-pytorch) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from requests->facenet-pytorch) (2024.2.2)\n",
            "Requirement already satisfied: torch==2.2.1 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from torchvision->facenet-pytorch) (2.2.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (4.10.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from torch==2.2.1->torchvision->facenet-pytorch) (2024.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from jinja2->torch==2.2.1->torchvision->facenet-pytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from sympy->torch==2.2.1->torchvision->facenet-pytorch) (1.3.0)\n",
            "Using cached facenet_pytorch-2.5.3-py3-none-any.whl (1.9 MB)\n",
            "Using cached torchvision-0.17.1-cp310-cp310-win_amd64.whl (1.2 MB)\n",
            "Installing collected packages: torchvision, facenet-pytorch\n",
            "Successfully installed facenet-pytorch-2.5.3 torchvision-0.17.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: MTCNN in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (0.1.1)\n",
            "Requirement already satisfied: keras>=2.0.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from MTCNN) (2.15.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from MTCNN) (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from opencv-python>=4.1.0->MTCNN) (1.26.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting tensorflow\n",
            "  Using cached tensorflow-2.15.0-cp310-cp310-win_amd64.whl.metadata (3.6 kB)\n",
            "Collecting tensorflow-intel==2.15.0 (from tensorflow)\n",
            "  Using cached tensorflow_intel-2.15.0-cp310-cp310-win_amd64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.25.3)\n",
            "Requirement already satisfied: setuptools in c:\\program files\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (63.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.62.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.28.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
            "  Using cached werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow)\n",
            "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
            "Using cached tensorflow-2.15.0-cp310-cp310-win_amd64.whl (2.1 kB)\n",
            "Using cached tensorflow_intel-2.15.0-cp310-cp310-win_amd64.whl (300.9 MB)\n",
            "Using cached werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
            "Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
            "Installing collected packages: werkzeug, pyasn1-modules, tensorflow-intel, tensorflow\n",
            "Successfully installed pyasn1-modules-0.3.0 tensorflow-2.15.0 tensorflow-intel-2.15.0 werkzeug-3.0.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade pip\n",
        "%pip install opencv-python\n",
        "# https://github.com/timesler/facenet-pytorch\n",
        "# In this repository, it also includs MTCNN for face detection prior to inference.\n",
        "# Making this the fastest MTCNN implementation available.\n",
        "%pip install facenet-pytorch\n",
        "%pip install MTCNN\n",
        "%pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting opencv-contrib-python\n",
            "  Using cached opencv_contrib_python-4.9.0.80-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from opencv-contrib-python) (1.26.4)\n",
            "Using cached opencv_contrib_python-4.9.0.80-cp37-abi3-win_amd64.whl (45.3 MB)\n",
            "Installing collected packages: opencv-contrib-python\n",
            "Successfully installed opencv-contrib-python-4.9.0.80\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install opencv-contrib-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wU9d3Z6aXD4h"
      },
      "source": [
        "2. Initialize MTCNN and FaceNet Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoyxwiLSgQ3m"
      },
      "outputs": [],
      "source": [
        "from facenet_pytorch import MTCNN, InceptionResnetV1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mR3SEQ9OdBVq"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# If required, create a face detection pipeline using MTCNN:\n",
        "mtcnn = MTCNN(image_size=576, margin=0)\n",
        "\n",
        "# Create an inception resnet (in eval mode):\n",
        "resnet = InceptionResnetV1(pretrained='vggface2').eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aYb68iAap9t"
      },
      "source": [
        "3. Process an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pk_KdtPZasA8"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "\n",
        "img = Image.open(r\"C:\\Users\\kamka\\OneDrive\\Desktop\\CMP6200 Project\\Facial Recognition using MTCNN and FaceNet\\sample_data\\Karhou2.jpg\")\n",
        "\n",
        "# Convert the image to RGB\n",
        "img_rgb = img.convert(\"RGB\")\n",
        "\n",
        "# Get cropped and prewhitened image tensor\n",
        "img_cropped = mtcnn(img_rgb, save_path=r\"C:\\Users\\kamka\\OneDrive\\Desktop\\CMP6200 Project\\Facial Recognition using MTCNN and FaceNet\\cropped_imgdata\\Karhou2.jpg\")\n",
        "\n",
        "# Calculate embedding (unsqueeze to add batch dimension)\n",
        "img_embedding = resnet(img_cropped.unsqueeze(0))\n",
        "\n",
        "# Or, if using for VGGFace2 classification\n",
        "resnet.classify = True\n",
        "img_probs = resnet(img_cropped.unsqueeze(0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Try with camera and make a bounding box around a face frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: opencv-python in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (4.9.0.80)\n",
            "Requirement already satisfied: opencv-python-headless in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (4.9.0.80)\n",
            "Requirement already satisfied: mtcnn in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (0.1.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from opencv-python) (1.26.4)\n",
            "Requirement already satisfied: keras>=2.0.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from mtcnn) (2.15.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: mtcnn in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (0.1.1)\n",
            "Requirement already satisfied: keras>=2.0.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from mtcnn) (2.15.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from mtcnn) (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from opencv-python>=4.1.0->mtcnn) (1.26.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tensorflow in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (2.15.0)\n",
            "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.25.3)\n",
            "Requirement already satisfied: setuptools in c:\\program files\\python310\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (63.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.62.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.28.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.8.3-cp310-cp310-win_amd64.whl.metadata (5.9 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Downloading contourpy-1.2.0-cp310-cp310-win_amd64.whl.metadata (5.8 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Downloading fonttools-4.49.0-cp310-cp310-win_amd64.whl.metadata (162 kB)\n",
            "     ---------------------------------------- 0.0/162.3 kB ? eta -:--:--\n",
            "     -------------------------------------- 162.3/162.3 kB 4.9 MB/s eta 0:00:00\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Downloading kiwisolver-1.4.5-cp310-cp310-win_amd64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (10.2.0)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
            "  Using cached pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Downloading matplotlib-3.8.3-cp310-cp310-win_amd64.whl (7.6 MB)\n",
            "   ---------------------------------------- 0.0/7.6 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 0.6/7.6 MB 18.2 MB/s eta 0:00:01\n",
            "   -------- ------------------------------- 1.6/7.6 MB 19.8 MB/s eta 0:00:01\n",
            "   ------------- -------------------------- 2.7/7.6 MB 21.1 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 3.9/7.6 MB 22.7 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 5.1/7.6 MB 23.2 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 6.3/7.6 MB 23.5 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 7.4/7.6 MB 23.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 7.6/7.6 MB 21.2 MB/s eta 0:00:00\n",
            "Downloading contourpy-1.2.0-cp310-cp310-win_amd64.whl (186 kB)\n",
            "   ---------------------------------------- 0.0/186.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 186.7/186.7 kB ? eta 0:00:00\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.49.0-cp310-cp310-win_amd64.whl (2.2 MB)\n",
            "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "   -------------------- ------------------- 1.1/2.2 MB 35.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  2.2/2.2 MB 34.5 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.2/2.2 MB 27.8 MB/s eta 0:00:00\n",
            "Downloading kiwisolver-1.4.5-cp310-cp310-win_amd64.whl (56 kB)\n",
            "   ---------------------------------------- 0.0/56.1 kB ? eta -:--:--\n",
            "   ---------------------------------------- 56.1/56.1 kB 3.1 MB/s eta 0:00:00\n",
            "Using cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
            "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
            "Successfully installed contourpy-1.2.0 cycler-0.12.1 fonttools-4.49.0 kiwisolver-1.4.5 matplotlib-3.8.3 pyparsing-3.1.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.4.1.post1-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\kamka\\appdata\\roaming\\python\\python310\\site-packages (from scikit-learn) (1.26.4)\n",
            "Collecting scipy>=1.6.0 (from scikit-learn)\n",
            "  Downloading scipy-1.12.0-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
            "     ---------------------------------------- 0.0/60.4 kB ? eta -:--:--\n",
            "     ---------------------------------------- 60.4/60.4 kB 3.3 MB/s eta 0:00:00\n",
            "Collecting joblib>=1.2.0 (from scikit-learn)\n",
            "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
            "  Using cached threadpoolctl-3.3.0-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading scikit_learn-1.4.1.post1-cp310-cp310-win_amd64.whl (10.6 MB)\n",
            "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
            "   -- ------------------------------------- 0.7/10.6 MB 14.4 MB/s eta 0:00:01\n",
            "   ------ --------------------------------- 1.7/10.6 MB 17.9 MB/s eta 0:00:01\n",
            "   ---------- ----------------------------- 2.8/10.6 MB 22.1 MB/s eta 0:00:01\n",
            "   -------------- ------------------------- 3.7/10.6 MB 21.6 MB/s eta 0:00:01\n",
            "   ------------------ --------------------- 4.8/10.6 MB 22.1 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 5.8/10.6 MB 21.7 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 6.9/10.6 MB 22.0 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 8.0/10.6 MB 22.2 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 9.0/10.6 MB 22.0 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 10.1/10.6 MB 22.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  10.6/10.6 MB 21.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 10.6/10.6 MB 20.5 MB/s eta 0:00:00\n",
            "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
            "Downloading scipy-1.12.0-cp310-cp310-win_amd64.whl (46.2 MB)\n",
            "   ---------------------------------------- 0.0/46.2 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.9/46.2 MB 29.4 MB/s eta 0:00:02\n",
            "   - -------------------------------------- 2.0/46.2 MB 26.0 MB/s eta 0:00:02\n",
            "   -- ------------------------------------- 3.1/46.2 MB 24.5 MB/s eta 0:00:02\n",
            "   --- ------------------------------------ 4.1/46.2 MB 23.8 MB/s eta 0:00:02\n",
            "   ---- ----------------------------------- 4.8/46.2 MB 22.1 MB/s eta 0:00:02\n",
            "   ----- ---------------------------------- 6.0/46.2 MB 22.7 MB/s eta 0:00:02\n",
            "   ------ --------------------------------- 7.0/46.2 MB 22.5 MB/s eta 0:00:02\n",
            "   ------ --------------------------------- 7.9/46.2 MB 22.0 MB/s eta 0:00:02\n",
            "   ------- -------------------------------- 9.1/46.2 MB 22.3 MB/s eta 0:00:02\n",
            "   -------- ------------------------------- 9.7/46.2 MB 21.4 MB/s eta 0:00:02\n",
            "   --------- ------------------------------ 10.8/46.2 MB 21.8 MB/s eta 0:00:02\n",
            "   ---------- ----------------------------- 11.9/46.2 MB 21.1 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 12.9/46.2 MB 21.1 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 13.7/46.2 MB 20.5 MB/s eta 0:00:02\n",
            "   ------------ --------------------------- 14.6/46.2 MB 21.1 MB/s eta 0:00:02\n",
            "   ------------- -------------------------- 15.6/46.2 MB 21.1 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 16.6/46.2 MB 20.5 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 17.3/46.2 MB 20.5 MB/s eta 0:00:02\n",
            "   --------------- ------------------------ 18.0/46.2 MB 20.5 MB/s eta 0:00:02\n",
            "   ---------------- ----------------------- 19.1/46.2 MB 19.8 MB/s eta 0:00:02\n",
            "   ----------------- ---------------------- 20.1/46.2 MB 20.5 MB/s eta 0:00:02\n",
            "   ------------------ --------------------- 21.2/46.2 MB 20.5 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 22.3/46.2 MB 20.5 MB/s eta 0:00:02\n",
            "   -------------------- ------------------- 23.5/46.2 MB 21.1 MB/s eta 0:00:02\n",
            "   --------------------- ------------------ 24.5/46.2 MB 21.8 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 25.7/46.2 MB 22.6 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 26.7/46.2 MB 21.9 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 27.9/46.2 MB 23.4 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 28.9/46.2 MB 24.2 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 29.8/46.2 MB 24.2 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 30.7/46.2 MB 23.4 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 31.5/46.2 MB 22.6 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 32.7/46.2 MB 22.5 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 33.5/46.2 MB 21.9 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 34.3/46.2 MB 21.1 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 35.0/46.2 MB 20.5 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 35.3/46.2 MB 19.3 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 35.5/46.2 MB 17.7 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 35.6/46.2 MB 17.2 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 35.9/46.2 MB 15.6 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 36.3/46.2 MB 14.9 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 36.5/46.2 MB 14.2 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 36.7/46.2 MB 13.6 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 37.0/46.2 MB 13.1 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 37.2/46.2 MB 12.6 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 37.5/46.2 MB 12.1 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 38.0/46.2 MB 11.7 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 39.2/46.2 MB 11.9 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 40.2/46.2 MB 11.9 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 41.2/46.2 MB 11.9 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 42.4/46.2 MB 12.1 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 43.5/46.2 MB 12.1 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 44.8/46.2 MB 12.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  45.9/46.2 MB 15.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------  46.2/46.2 MB 15.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------  46.2/46.2 MB 15.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 46.2/46.2 MB 13.6 MB/s eta 0:00:00\n",
            "Using cached threadpoolctl-3.3.0-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
            "Successfully installed joblib-1.3.2 scikit-learn-1.4.1.post1 scipy-1.12.0 threadpoolctl-3.3.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install opencv-python opencv-python-headless mtcnn\n",
        "%pip install mtcnn\n",
        "%pip install tensorflow\n",
        "%pip install matplotlib\n",
        "%pip install scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Open Camera to video capture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "stream = cv2.VideoCapture(0)\n",
        "\n",
        "if not stream.isOpened():\n",
        "    print(\"No stream available\")\n",
        "    exit()\n",
        "    \n",
        "while (True):\n",
        "    ret, frame = stream.read()\n",
        "    if not ret:\n",
        "        print(\"No stream available\")\n",
        "        break\n",
        "        \n",
        "    cv2.imshow(\"Webcam\", frame)\n",
        "    if cv2.waitKey(1) == ord('q'):\n",
        "        break\n",
        "        \n",
        "stream.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +\n",
        "                    \"haarcascade_frontalface_default.xml\")\n",
        "smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +\n",
        "                    \"haarcascade_smile.xml\")\n",
        "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades +\n",
        "                    \"haarcascade_eye.xml\")\n",
        "\n",
        "def detect_features(frame):\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
        "            # You can also specify minSize and maxSize\n",
        "    for (x, y, w, h) in faces:\n",
        "        frame = cv2.rectangle(frame, (x, y), (x+w, y+h),\n",
        "                            color=(0, 255, 0), thickness=5)\n",
        "        face = frame[y : y+h, x : x+w]\n",
        "        gray_face = gray[y : y+h, x : x+w]\n",
        "        smiles = smile_cascade.detectMultiScale(gray_face, \n",
        "                            2.5, minNeighbors=9)\n",
        "        for (xp, yp, wp, hp) in smiles:\n",
        "            face = cv2.rectangle(face, (xp, yp), (xp+wp, yp+hp),\n",
        "                    color=(0, 0, 255), thickness=5)\n",
        "        \n",
        "        eyes = eye_cascade.detectMultiScale(gray_face, \n",
        "                    2.5, minNeighbors=7)\n",
        "        for (xp, yp, wp, hp) in eyes:\n",
        "            face = cv2.rectangle(face, (xp, yp), (xp+wp, yp+hp),\n",
        "                    color=(255, 0, 0), thickness=5)\n",
        "    \n",
        "    return frame\n",
        "\n",
        "stream = cv2.VideoCapture(0)\n",
        "\n",
        "if not stream.isOpened():\n",
        "    print(\"No stream :(\")\n",
        "    exit()\n",
        "\n",
        "fps = stream.get(cv2.CAP_PROP_FPS)\n",
        "width = int(stream.get(3))\n",
        "height = int(stream.get(4))\n",
        "\n",
        "# list of FourCC video codes: https://softron.zendesk.com/hc/en-us/articles/207695697-List-of-FourCC-codes-for-video-codecs\n",
        "output = cv2.VideoWriter(\"assets/6_facial_detection.mp4\",\n",
        "            cv2.VideoWriter_fourcc('m', 'p', '4', 'v'),\n",
        "            fps=fps, frameSize=(width, height))\n",
        "\n",
        "while(True):\n",
        "    ret, frame = stream.read()\n",
        "    if not ret:\n",
        "        print(\"No more stream :(\")\n",
        "        break\n",
        "    \n",
        "    frame = detect_features(frame)\n",
        "    output.write(frame)\n",
        "    cv2.imshow(\"Webcam!\", frame)\n",
        "    if cv2.waitKey(1) == ord('q'):\n",
        "        break\n",
        "\n",
        "stream.release()\n",
        "cv2.destroyAllWindows() #!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "from mtcnn import MTCNN\n",
        "\n",
        "# Initialize MTCNN for face detection\n",
        "detector = MTCNN()\n",
        "\n",
        "def detect_features(frame):\n",
        "    # Convert frame to RGB (MTCNN expects RGB images)\n",
        "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    # Detect faces using MTCNN\n",
        "    faces = detector.detect_faces(rgb_frame)\n",
        "    \n",
        "    # Draw rectangles around detected faces\n",
        "    for face in faces:\n",
        "        x, y, w, h = face['box']\n",
        "        frame = cv2.rectangle(frame, (x, y), (x+w, y+h), color=(0, 255, 0), thickness=5)\n",
        "        \n",
        "        # Draw rectangles around detected eyes (optional)\n",
        "        for key, value in face['keypoints'].items():\n",
        "            frame = cv2.rectangle(frame, (value[0]-5, value[1]-5), (value[0]+5, value[1]+5), color=(255, 0, 0), thickness=2)\n",
        "    \n",
        "    return frame\n",
        "\n",
        "stream = cv2.VideoCapture(0)\n",
        "\n",
        "if not stream.isOpened():\n",
        "    print(\"No stream :(\")\n",
        "    exit()\n",
        "\n",
        "fps = stream.get(cv2.CAP_PROP_FPS)\n",
        "width = int(stream.get(3))\n",
        "height = int(stream.get(4))\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "output = cv2.VideoWriter(\"assets/6_facial_detection.mp4\",\n",
        "            cv2.VideoWriter_fourcc('m', 'p', '4', 'v'),\n",
        "            fps=fps, frameSize=(width, height))\n",
        "\n",
        "while(True):\n",
        "    ret, frame = stream.read()\n",
        "    if not ret:\n",
        "        print(\"No more stream :(\")\n",
        "        break\n",
        "    \n",
        "    frame = detect_features(frame)\n",
        "    output.write(frame)\n",
        "    cv2.imshow(\"Webcam!\", frame)\n",
        "    if cv2.waitKey(1) == ord('q'):\n",
        "        break\n",
        "\n",
        "stream.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\kamka\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'Image' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Load the sample picture\u001b[39;00m\n\u001b[0;32m     16\u001b[0m sample_image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mkamka\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCMP6200 Project\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mFacial Recognition using MTCNN and FaceNet\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcropped_imgdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mKarhou2.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 17\u001b[0m sample_image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241m.\u001b[39mopen(sample_image_path)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Convert the PIL Image to a tensor and normalize it\u001b[39;00m\n\u001b[0;32m     20\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m     21\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m160\u001b[39m, \u001b[38;5;241m160\u001b[39m)),  \u001b[38;5;66;03m# Resize to the input size that FaceNet expects\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),  \u001b[38;5;66;03m# This also scales pixel values to [0, 1]\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m], std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m])  \u001b[38;5;66;03m# Adjust these values based on the expected normalization parameters for your model\u001b[39;00m\n\u001b[0;32m     24\u001b[0m ])\n",
            "\u001b[1;31mNameError\u001b[0m: name 'Image' is not defined"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "from mtcnn import MTCNN\n",
        "from facenet_pytorch import MTCNN as FaceNetMTCNN, InceptionResnetV1\n",
        "from PIL import Image as PILImage  # Alias PIL's Image\n",
        "from torchvision import transforms\n",
        "from IPython.display import display, Image as IPyImage  # Alias IPython's Image\n",
        "import io\n",
        "\n",
        "\n",
        "\n",
        "# Initialize MTCNN from facenet_pytorch\n",
        "mtcnn = FaceNetMTCNN()\n",
        "facenet_model = InceptionResnetV1(pretrained='vggface2').eval()\n",
        "\n",
        "# Load the sample picture\n",
        "sample_image_path = r\"C:\\Users\\kamka\\OneDrive\\Desktop\\CMP6200 Project\\Facial Recognition using MTCNN and FaceNet\\cropped_imgdata\\Karhou2.jpg\"\n",
        "sample_image = Image.open(sample_image_path)\n",
        "\n",
        "# Convert the PIL Image to a tensor and normalize it\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((160, 160)),  # Resize to the input size that FaceNet expects\n",
        "    transforms.ToTensor(),  # This also scales pixel values to [0, 1]\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Adjust these values based on the expected normalization parameters for your model\n",
        "])\n",
        "\n",
        "sample_image_tensor = transform(sample_image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "# Extract face embeddings from the sample picture\n",
        "sample_image_embedding = facenet_model(sample_image_tensor).detach().numpy()\n",
        "\n",
        "# Define a threshold for face similarity\n",
        "threshold = 0.6\n",
        "\n",
        "def detect_and_match_faces(frame):\n",
        "    # Detect faces using MTCNN\n",
        "    boxes, _ = mtcnn.detect(frame)\n",
        "    \n",
        "    if boxes is not None:\n",
        "        for box in boxes:\n",
        "            # Extract face from the frame\n",
        "            x1, y1, x2, y2 = map(int, box)\n",
        "            face = frame[y1:y2, x1:x2]\n",
        "            \n",
        "            # Convert the face to a PIL Image and apply transforms\n",
        "            face_image_pil = Image.fromarray(face)\n",
        "            face_image_tensor = transform(face_image_pil).unsqueeze(0)  # Apply the same transformations\n",
        "            \n",
        "            # Extract face embedding from the detected face\n",
        "            face_embedding = facenet_model(face_image_tensor).detach().numpy()\n",
        "\n",
        "            # Calculate similarity between the embeddings\n",
        "            similarity = cosine_similarity(sample_image_embedding, face_embedding)[0][0]\n",
        "            \n",
        "            # Display indications based on similarity\n",
        "            if similarity >= threshold:\n",
        "                cv2.putText(frame, \"Match\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "            else:\n",
        "                cv2.putText(frame, \"No match\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
        "    \n",
        "    return frame\n",
        "\n",
        "def show_image_in_notebook(image):\n",
        "    is_success, buffer = cv2.imencode(\".jpg\", image)\n",
        "    io_buf = io.BytesIO(buffer)\n",
        "    display(Image(io_buf.read()))\n",
        "\n",
        "stream = cv2.VideoCapture(0)\n",
        "\n",
        "if not stream.isOpened():\n",
        "    print(\"No stream :(\")\n",
        "    exit()\n",
        "\n",
        "fps = stream.get(cv2.CAP_PROP_FPS)\n",
        "width = int(stream.get(3))\n",
        "height = int(stream.get(4))\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "output = cv2.VideoWriter(\"assets/6_facial_detection.mp4\",\n",
        "            cv2.VideoWriter_fourcc('m', 'p', '4', 'v'),\n",
        "            fps=fps, frameSize=(width, height))\n",
        "\n",
        "while True:\n",
        "    ret, frame = stream.read()\n",
        "    if not ret:\n",
        "        print(\"No more stream :(\")\n",
        "        break\n",
        "    \n",
        "    frame = detect_and_match_faces(frame)\n",
        "    output.write(frame)\n",
        "    #cv2.imshow(\"Webcam\", frame)\n",
        "    show_image_in_notebook(frame)\n",
        "    if cv2.waitKey(1) == ord('q'):\n",
        "        break\n",
        "\n",
        "stream.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "from facenet_pytorch import InceptionResnetV1, MTCNN\n",
        "from PIL import Image as PILImage\n",
        "from torchvision import transforms\n",
        "from IPython.display import display, Image as IPyImage\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Initialize MTCNN for face detection \n",
        "mtcnn = MTCNN()\n",
        "# Initialize FaceNet model\n",
        "facenet_model = InceptionResnetV1(pretrained='vggface2').eval()\n",
        "\n",
        "# Load the sample image and preprocess it\n",
        "sample_image_path = r\"C:\\Users\\kamka\\OneDrive\\Desktop\\CMP6200 Project\\Facial Recognition using MTCNN and FaceNet\\cropped_imgdata\\Karhou1.jpg\"\n",
        "# Sample image has to be the cropped image from step 3's processing image\n",
        "sample_image = PILImage.open(sample_image_path)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((160, 160)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "])\n",
        "sample_image_tensor = transform(sample_image).unsqueeze(0)\n",
        "sample_image_embedding = facenet_model(sample_image_tensor).detach().numpy()\n",
        "\n",
        "# Define a threshold for face similarity\n",
        "threshold = 0.6\n",
        "\n",
        "# Define function for detect face and match face similarity\n",
        "def detect_and_match_faces(frame):\n",
        "    try:\n",
        "        # Detect faces using MTCNN\n",
        "        boxes, _ = mtcnn.detect(frame)\n",
        "\n",
        "        if boxes is not None:\n",
        "            for box in boxes:\n",
        "                x1, y1, x2, y2 = map(int, box)\n",
        "                face = frame[y1:y2, x1:x2]\n",
        "\n",
        "                # Convert face to PIL Image and preprocess\n",
        "                face_image_pil = PILImage.fromarray(face)\n",
        "                face_image_tensor = transform(face_image_pil).unsqueeze(0)\n",
        "\n",
        "                # Extract face embedding using FaceNet Model\n",
        "                face_embedding = facenet_model(face_image_tensor).detach().numpy()\n",
        "\n",
        "                # Calculate similarity\n",
        "                similarity = cosine_similarity(sample_image_embedding, face_embedding)[0][0]\n",
        "\n",
        "\n",
        "\n",
        "                # Display match indication based on similarity\n",
        "                if similarity >= threshold:\n",
        "                    cv2.rectangle(frame, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=5)\n",
        "                    cv2.putText(frame, \"Match\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "                else:\n",
        "                    cv2.rectangle(frame, (x1, y1), (x2, y2), color=(0, 0, 255), thickness=5)\n",
        "                    cv2.putText(frame, \"No match\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing frame: {e}\")\n",
        "\n",
        "    return frame\n",
        "\n",
        "# Open video capture\n",
        "stream = cv2.VideoCapture(0)\n",
        "\n",
        "if not stream.isOpened():\n",
        "    print(\"No stream :(\")\n",
        "    exit()\n",
        "\n",
        "fps = stream.get(cv2.CAP_PROP_FPS)\n",
        "width = int(stream.get(3))\n",
        "height = int(stream.get(4))\n",
        "\n",
        "# Define VideoWriter object\n",
        "output = cv2.VideoWriter(\"assets/6_facial_detection.mp4\", cv2.VideoWriter_fourcc('m', 'p', '4', 'v'), fps=fps, frameSize=(width, height))\n",
        "\n",
        "while True:\n",
        "    ret, frame = stream.read()\n",
        "    if not ret:\n",
        "        print(\"No more stream :(\")\n",
        "        break\n",
        "\n",
        "    frame = detect_and_match_faces(frame)\n",
        "    output.write(frame)\n",
        "    cv2.imshow(\"Webcam\", frame)\n",
        "    if cv2.waitKey(1) == ord('q'):\n",
        "        break\n",
        "\n",
        "stream.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
